{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSA_textClassification_toy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mesahwi/TextAnlaysis/blob/master/Learning/LSA_textClassification_toy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9vKFBUHpWsX",
        "colab_type": "text"
      },
      "source": [
        "Topic Modelling, for testing purposes (English texts used)\n",
        "\n",
        "\n",
        "\n",
        "Rough Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lEnosJNs0kh",
        "colab_type": "text"
      },
      "source": [
        "Step 0 : Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8a_TKlwsyst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.feature_extraction.text import HashingVectorizer\n",
        "# from sklearn.feature_extraction.text import TfidfTransformer\n",
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "categories = [\n",
        "    'talk.politics.mideast',\n",
        "    'rec.sport.baseball',\n",
        "    'sci.electronics'\n",
        "]\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYi_guEgphlY",
        "colab_type": "text"
      },
      "source": [
        "Step 1 : Gather Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KejXyQXnpTDH",
        "colab_type": "code",
        "outputId": "81d88d47-8c1e-4b34-c359-dc3aeb13ec5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "data_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
        "\n",
        "length = len(np.unique(data_train.target))\n",
        "for i in range(0, length):\n",
        "  n = len(np.where(data_train.target==0)[0])\n",
        "  print(categories[i], ' : ', n)\n",
        "  i=i+1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "talk.politics.mideast  :  597\n",
            "rec.sport.baseball  :  597\n",
            "sci.electronics  :  597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCrgoUbJtcrG",
        "colab_type": "code",
        "outputId": "755f6a0e-a225-4c10-bdb5-386825731fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "data_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
        "\n",
        "length = len(np.unique(data_test.target))\n",
        "for i in range(0, length):\n",
        "  n = len(np.where(data_test.target==0)[0])\n",
        "  print(categories[i], ' : ', n)\n",
        "  i=i+1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "talk.politics.mideast  :  397\n",
            "rec.sport.baseball  :  397\n",
            "sci.electronics  :  397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbLh4yulp2UU",
        "colab_type": "text"
      },
      "source": [
        "Step 2 : Preprocess\n",
        " 1. Create a tf-idf (or word-document) matrix\n",
        " 2. Run a SVD on the matrix (A = u Sig v', where \\\n",
        "      u = Word matrix for Topic \\\\\n",
        "      Sig = Topic Strength \\\\\n",
        "      v = Document matrix for Topic)\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiVdFHZGuIa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf-idf matrix\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(data_train.data)  #X is in CSR format\n",
        "# print(vectorizer.get_feature_names())\n",
        "\n",
        "#SVD - naive : ARPACK\n",
        "# XArr = X.toarray()\n",
        "# U, sig, Vt = np.linalg.svd(XArr)\n",
        "# sigDiag = np.diag(sig)\n",
        "\n",
        "\n",
        "#SVD - faster : randomized solver\n",
        "numComp = len(np.unique(data_train.target))\n",
        "svd = TruncatedSVD(n_components = numComp, n_iter=100)\n",
        "normalizer = Normalizer(copy=False)\n",
        "lsa = make_pipeline(svd, normalizer)\n",
        "\n",
        "X_train = lsa.fit_transform(X) # ~~ np.dot(sigDiag[:numComp, :numComp], Vt[:numComp, :])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDIxGhiSFJ-p",
        "colab_type": "text"
      },
      "source": [
        "It's worth noting that if you try to run a naive SVD with a sizeable dataset, the memory explodes, so making use of Truncated SVD is recommended"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkGrVTvPZdyR",
        "colab_type": "text"
      },
      "source": [
        "Step 3 : Train! (and test performance on training data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n4QcavC_yAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing performance of model on training data\n",
        "gnb = GaussianNB()\n",
        "gnbfit = gnb.fit(X_train, data_train.target)\n",
        "y_retro_NB = gnbfit.predict(X_train)\n",
        "\n",
        "svm = SVC()\n",
        "svmfit = svm.fit(X_train, data_train.target)\n",
        "y_retro_SVM = svmfit.predict(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II8e4Cai0fNc",
        "colab_type": "code",
        "outputId": "e797bfaf-5eb2-4732-e6bb-b894b72c4179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "dif = y_retro_NB - data_train.target\n",
        "val, cnt = np.unique(dif, return_counts = True)\n",
        "correctN = dict(zip(val, cnt))[0]\n",
        "print ('Training set Performance NB : ', correctN / sum(cnt))\n",
        "\n",
        "dif = y_retro_SVM - data_train.target\n",
        "val, cnt = np.unique(dif, return_counts = True)\n",
        "correctN = dict(zip(val, cnt))[0]\n",
        "print ('Training set Performance SVM : ', correctN / sum(cnt))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set Performance NB :  0.8664383561643836\n",
            "Training set Performance SVM :  0.8635844748858448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjtD-4ziYCsA",
        "colab_type": "text"
      },
      "source": [
        "Step 4 : Test performance on testing dataset\n",
        "\n",
        "1.   Preprocess testing dataset\n",
        "2.   Test performance\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiLJLXBDauRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X2 = vectorizer.fit_transform(data_test.data)\n",
        "X_test = lsa.fit_transform(X2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iloCHUgNUMS4",
        "colab_type": "code",
        "outputId": "709715b0-2055-44a3-b29b-cb480bda1609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_pred_NB = gnbfit.predict(X_test)\n",
        "y_pred_SVM = svmfit.predict(X_test)\n",
        "\n",
        "\n",
        "dif = y_pred_NB - data_test.target\n",
        "val, cnt = np.unique(dif, return_counts = True)\n",
        "correctN = dict(zip(val, cnt))[0]\n",
        "print ('Testing set Performance NB : ', correctN / sum(cnt))\n",
        "\n",
        "dif = y_pred_SVM - data_test.target\n",
        "val, cnt = np.unique(dif, return_counts = True)\n",
        "correctN = dict(zip(val, cnt))[0]\n",
        "print ('Testing set Performance SVM : ', correctN / sum(cnt))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing set Performance NB :  0.8001715265866209\n",
            "Testing set Performance SVM :  0.8456260720411664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h107HYAhctwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}